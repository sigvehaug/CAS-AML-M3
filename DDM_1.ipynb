{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Denoising Diffusion Models"
      ],
      "metadata": {
        "id": "ICg6dDRIShAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "CAS on Advanced Machine Learning <br>\n",
        "Data Science Lab, University of Bern, 2023<br>\n",
        "Prepared by Dr. Mykhailo Vladymyrov.\n",
        "\n",
        "</p>\n",
        "\n",
        "This work is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n",
        "Based on the HuggingFace tutorials and reference manual"
      ],
      "metadata": {
        "id": "8R7S6Mk9SaRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libs installation"
      ],
      "metadata": {
        "id": "4uVrq6Z-SmdQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdq1K-ho0362"
      },
      "outputs": [],
      "source": [
        "pip install transformers diffusers accelerate einops datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Cats generation model inspection"
      ],
      "metadata": {
        "id": "S9p5qOZ-GCYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The aim of this tutorial is to understand the principle and components of sample generation using diffusion models"
      ],
      "metadata": {
        "id": "DngjbvvFS95_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import DDPMPipeline\n",
        "from diffusers import DDPMScheduler, UNet2DModel\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import einops as eo\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "mQT-_Irw1KKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_iterable(obj):\n",
        "    if type(obj) == str:\n",
        "      return False\n",
        "    try:\n",
        "        iter(obj)\n",
        "    except Exception:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "def plot_many(ys, xs=None, labels=None, xlabels=None, ylabels=None, titles=None, legend_loc='best', single_plot_sz=6):\n",
        "    \"\"\"\n",
        "    plot many lines in one plot\n",
        "    \"\"\"\n",
        "    n_plots = len(ys)\n",
        "\n",
        "    def prep_for_n_plots(var, n_plots):\n",
        "        if var is None:\n",
        "            return [None] * n_plots\n",
        "        elif is_iterable(var):\n",
        "            assert len(var) == n_plots, f'len({var}) != {n_plots}'\n",
        "            return var\n",
        "        else:\n",
        "            return [var] * n_plots\n",
        "\n",
        "    xs = prep_for_n_plots(xs, n_plots)\n",
        "    labels = prep_for_n_plots(labels, n_plots)\n",
        "    xlabels = prep_for_n_plots(xlabels, n_plots)\n",
        "    ylabels = prep_for_n_plots(ylabels, n_plots)\n",
        "    titles = prep_for_n_plots(titles, n_plots)\n",
        "    legend_loc = prep_for_n_plots(legend_loc, n_plots)\n",
        "\n",
        "    if not is_iterable(single_plot_sz):\n",
        "        single_plot_sz = [single_plot_sz, single_plot_sz]\n",
        "\n",
        "    figsize = [single_plot_sz[0] * n_plots, single_plot_sz[1]]\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=n_plots, figsize=figsize)\n",
        "\n",
        "    if n_plots==1:\n",
        "      ax = [ax]\n",
        "\n",
        "    for axi, x, y, label, xlabel, ylabel, title, loc in zip(ax, xs, ys, labels, xlabels, ylabels, titles, legend_loc):\n",
        "        if y is None:\n",
        "            # placeholder for empty plot - to be filled by the caller\n",
        "            continue\n",
        "\n",
        "        if is_iterable(y[0]):\n",
        "            n = len(y)\n",
        "            x = prep_for_n_plots(x, n)\n",
        "            label = prep_for_n_plots(label, n)\n",
        "\n",
        "            for xi, yi, labeli in zip(x, y, label):\n",
        "                if xi is None:\n",
        "                  axi.plot(yi, label=labeli)\n",
        "                else:\n",
        "                  axi.plot(xi, yi, label=labeli)\n",
        "            axi.legend(loc=loc)\n",
        "        else:\n",
        "            if x is None:\n",
        "              axi.plot(y, label=label)\n",
        "            else:\n",
        "              axi.plot(x, y, label=label)\n",
        "        axi.set_xlabel(xlabel)\n",
        "        axi.set_ylabel(ylabel)\n",
        "        axi.set_title(title)\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda:0')  # use first available GPU\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "    return device"
      ],
      "metadata": {
        "id": "6aduZyVW_VX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a generation pipeline based on a pretrained model on the cat images dataset."
      ],
      "metadata": {
        "id": "p8ZWKpbcXNuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = get_device()\n",
        "\n",
        "ddpm = DDPMPipeline.from_pretrained(\"google/ddpm-cat-256\", use_safetensors=True).to(device)"
      ],
      "metadata": {
        "id": "zDhQ4GhP1WOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Piplene contains 2 parts: denoising model and the scheduler.\n",
        "Scheduler is taking care of the values of noise - beta(t), and corresponding updates to the sample.\n",
        "\n",
        "See the docstreeng for more info."
      ],
      "metadata": {
        "id": "4YenF9IZYGRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call to the pipeline - genarates a sample, and returns `ImagePipelineOutput` - dictionary-like object."
      ],
      "metadata": {
        "id": "gvI0HQKpY0ET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ddpm(num_inference_steps=5)"
      ],
      "metadata": {
        "id": "Ik3SSkmYXr1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = ddpm(num_inference_steps=5).images[0]\n",
        "image"
      ],
      "metadata": {
        "id": "5iWVmX7aXomH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 steps is not enough to generate meaningful sample. Try more."
      ],
      "metadata": {
        "id": "LjlP8ETSZLoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Components of denoising pipeline"
      ],
      "metadata": {
        "id": "rcRCn9g2ZanQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = DDPMScheduler.from_pretrained(\"google/ddpm-cat-256\")\n",
        "model = UNet2DModel.from_pretrained(\"google/ddpm-cat-256\", use_safetensors=True).to(device)"
      ],
      "metadata": {
        "id": "spT2ewjq1bMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler.set_timesteps(20)  # number of diffusion steps"
      ],
      "metadata": {
        "id": "pA1qBro816QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler\n"
      ],
      "metadata": {
        "id": "v81TcRt918RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler.timesteps"
      ],
      "metadata": {
        "id": "oRbIgstW7DYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The beta is not constant during all the denoising steps:"
      ],
      "metadata": {
        "id": "maRtuLSkZmWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_many(ys=[\n",
        "            scheduler.alphas.cpu().numpy(),\n",
        "            scheduler.alphas_cumprod.cpu().numpy(),\n",
        "            scheduler.betas.cpu().numpy(),\n",
        "            scheduler.timesteps.cpu().numpy(),\n",
        "            scheduler.betas.cpu().numpy() / np.sqrt(1-(scheduler.alphas_cumprod.cpu().numpy())**2)\n",
        "                ],\n",
        "          titles=['alphas', 'alphas_cumprod', 'betas', 'timesteps', 'beta/sigma'],\n",
        "          single_plot_sz=5);"
      ],
      "metadata": {
        "id": "VQ-5A7P819RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size = model.config.sample_size\n",
        "noise = torch.randn((1, 3, sample_size, sample_size)).to(device)"
      ],
      "metadata": {
        "id": "RiouaTCg2HWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5, 1))\n",
        "plt.hist(noise.cpu().numpy().flatten(), 1000);"
      ],
      "metadata": {
        "id": "WLvk7Bx1Byw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_np_showable(pt_img):\n",
        "  return (eo.rearrange(pt_img.detach().cpu().numpy()[0], 'c w h -> w h c')/3+.5).clip(0., 1.)"
      ],
      "metadata": {
        "id": "UzGylqtSH1CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will visualize the evolution of sample and noise steps over denoising course:"
      ],
      "metadata": {
        "id": "LEIOb7I-afV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = noise\n",
        "\n",
        "for t in tqdm.notebook.tqdm(scheduler.timesteps):\n",
        "  with torch.no_grad():\n",
        "    mod_out = model(x, t)\n",
        "    noisy_residual = mod_out.sample  # model predicts noise step\n",
        "\n",
        "    # scheduler step outputs a dictionary with 2 things:\n",
        "    # 1-step sample update\n",
        "    # and extrapolation to fully denoised sample\n",
        "    ddpm_sched_out_dict = scheduler.step(noisy_residual, t, x)\n",
        "    previous_noisy_sample = ddpm_sched_out_dict.prev_sample\n",
        "    pred_orig_sample = ddpm_sched_out_dict.pred_original_sample\n",
        "\n",
        "\n",
        "    x_np = to_np_showable(x)\n",
        "    nr_np = to_np_showable(noisy_residual)\n",
        "    pns_np = to_np_showable(previous_noisy_sample)\n",
        "    pos_np = to_np_showable(pred_orig_sample)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 4, figsize=(16, 4))\n",
        "    for axi, im, ttl in zip(ax,\n",
        "                            [x_np, nr_np, pns_np, pos_np],\n",
        "                            ['input image', 'noise step', 'updated image', 'expected final denoised']\n",
        "                            ):\n",
        "      axi.imshow(im)\n",
        "      axi.set_title(ttl)\n",
        "    plt.suptitle(f't={t.numpy()}')\n",
        "    plt.show()\n",
        "\n",
        "    x = previous_noisy_sample"
      ],
      "metadata": {
        "id": "Un6t13xFCsgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Exercise:\n",
        "\n",
        "* Increase step number\n",
        "* visualize distribution of sample pixels and noise at each step\n",
        "* Try finding more efficient scheduler"
      ],
      "metadata": {
        "id": "XoZsr-tfa8cv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sDhZD9vXb-gb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}