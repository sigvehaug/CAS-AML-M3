{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRAF9H1wvW9-"
      },
      "source": [
        "# **Deep Reinforcement Learning**\n",
        "\n",
        "Objectives: Train Deep Reinforcement Learning methods on the [Lunar Lander](https://www.gymlibrary.dev/environments/box2d/lunar_lander) and [Bipedal Walker](https://www.gymlibrary.dev/environments/box2d/bipedal_walker/) OpenAI Gym environments\n",
        "\n",
        "1.   Improve the DQN agent already implemented by modifying the DQN, or by searching for better parameters\n",
        "2.   Apply Policy-based/Actor Critic agent to the Bipedal Walker environment\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J35LkLsOQzP"
      },
      "source": [
        "To use GPU, set `Edit / Notebook settings / Hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4T0wPS2xjDf"
      },
      "source": [
        "Install needed Python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6SnH6p5xpdY",
        "outputId": "f977ee80-0254-46b5-8b30-585ca380dcbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym[box2D] in /usr/local/lib/python3.7/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2D]) (5.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2D]) (1.5.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[box2D]) (0.0.8)\n",
            "  Downloading pygame-2.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.3 MB 94 kB/s \n",
            "\u001b[?25hCollecting box2d-py==2.3.5\n",
            "  Downloading box2d_py-2.3.5-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 46.9 MB/s \n",
            "\u001b[?25hCollecting swig==4.*\n",
            "  Downloading swig-4.0.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[box2D]) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[box2D]) (3.8.1)\n",
            "Installing collected packages: swig, pygame, box2d-py\n",
            "Successfully installed box2d-py-2.3.5 pygame-2.1.0 swig-4.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pygame gym[box2D] numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYKnoiSGHTuj"
      },
      "source": [
        "Import basic Python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wAiFrJhyHTDE"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import pygame\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38s_n3bxQjpO"
      },
      "source": [
        "Mount Google Drive for saving results (not needed if running the notebook locally)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrEvXkN-h9KV",
        "outputId": "64546f88-3f74-48ca-a6b6-835d7a044a28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"         # default location for the drive\n",
        "\n",
        "drive.mount(ROOT)              # we mount the google drive at /content/drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1brvbQhdeiC"
      },
      "source": [
        "## Video Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4B9aEomAT45U"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import base64\n",
        "from IPython import display as ipythondisplay\n",
        "from gym.wrappers import RecordVideo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ScgX7DejxcPq"
      },
      "outputs": [],
      "source": [
        "# Set up fake display; otherwise rendering will fail on Google Colab\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3nv7O8oeQdCQ"
      },
      "outputs": [],
      "source": [
        "def show_videos(video_path='', prefix=''):\n",
        "  html = []\n",
        "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zJvX9szqTzNm"
      },
      "outputs": [],
      "source": [
        "def record_video_randpol(env, video_length=0, step_trigger=None, episode_trigger=None,  prefix='', video_folder='videos/'):\n",
        "\n",
        "  video_env = RecordVideo(env, \n",
        "                         video_folder=video_folder,\n",
        "                         episode_trigger=episode_trigger,\n",
        "                         step_trigger=step_trigger,\n",
        "                         video_length=video_length,\n",
        "                         name_prefix=prefix,\n",
        "                         new_step_api=True\n",
        "                         )\n",
        "  \n",
        "  observation = video_env.reset()\n",
        "\n",
        "  step = 0\n",
        "  ep = 0\n",
        "\n",
        "  while True:\n",
        "\n",
        "    if _iterate_condition(step, ep, video_length=video_length, step_trigger=step_trigger, episode_trigger=episode_trigger):\n",
        "\n",
        "      observation, reward, terminated, _, info = video_env.step(env.action_space.sample())\n",
        "      step += 1\n",
        "\n",
        "      if terminated:\n",
        "        observation = video_env.reset()\n",
        "        ep += 1\n",
        "        step = 0\n",
        "    \n",
        "    else:\n",
        "      break\n",
        "      \n",
        "  video_env.close()\n",
        "\n",
        "# Utility function for checking stopping condition\n",
        "def _iterate_condition(step, ep, video_length=0, step_trigger=None, episode_trigger=None):\n",
        "\n",
        "  if video_length is not 0:\n",
        "    go = True if step < video_length else False\n",
        "    return go\n",
        "\n",
        "  if step_trigger is not None:\n",
        "    go = step_trigger(step)\n",
        "    return go\n",
        "\n",
        "  if episode_trigger is not None:\n",
        "    go = episode_trigger(ep)\n",
        "    return go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "k0cdLPuMaOV3"
      },
      "outputs": [],
      "source": [
        "# Set up fake display; otherwise rendering will fail on Google Colab\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_ckrXed3aOV4"
      },
      "outputs": [],
      "source": [
        "def show_videos(video_path='', prefix=''):\n",
        "  html = []\n",
        "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kirx0mcGlE24"
      },
      "source": [
        "# **1) Improve DQN Agent on `Lunar-Lander-v2`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "739UDEiudoGu"
      },
      "source": [
        "## Inspect `LunarLander-v2` environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EU4Lkhb1P8e"
      },
      "source": [
        "Initialize environment with discrete action space (necessary for DQN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PhOFHEAxaOV4"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\n",
        "    \"LunarLander-v2\",\n",
        "    continuous = False,\n",
        "    enable_wind = False,\n",
        "    new_step_api=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prFN0U5P1JFY"
      },
      "source": [
        "Record and show video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Sj9azwZTLArf"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "is_colab = 'google.colab' in sys.modules\n",
        "root_dir ='drive/MyDrive/CASAdvancedML' if is_colab else '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "PltIq6dqcfpc",
        "outputId": "66b87a80-6854-4e77-fabc-f09a3d861906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/wrappers/record_video.py:79: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/drive/MyDrive/CASAdvancedML/Videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  f\"Overwriting existing videos at {self.video_folder} folder \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/wrappers/monitoring/video_recorder.py:79: DeprecationWarning: \u001b[33mWARN: Recording ability for environment LunarLander-v2 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.\u001b[0m\n",
            "  f\"Recording ability for environment {env.spec.id} initialized with `render_mode=None` is marked \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:44: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:44: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video alt=\"drive/MyDrive/CASAdvancedML/Videos/lunland_random-episode-0.mp4\" autoplay \n",
              "                    loop controls style=\"height: 400px;\">\n",
              "                    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "                </video>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "video_folder = os.path.join(root_dir, 'Videos')\n",
        "os.makedirs(video_folder, exist_ok =True)\n",
        "\n",
        "prefix = 'lunland_random'\n",
        "\n",
        "record_video_randpol(env,\n",
        "                     video_length=0,\n",
        "                     episode_trigger=lambda ep: ep == 0,\n",
        "                     step_trigger=None,\n",
        "                     prefix=prefix,\n",
        "                     video_folder=video_folder)\n",
        "\n",
        "show_videos(video_folder, prefix=prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0iGhApXcycX",
        "outputId": "3d5afe73-2ffc-48bc-b84e-e56e86dcc682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The action space of the environment is of dimension: 4\n",
            "The observation space of the environment is of dimension (8,)\n"
          ]
        }
      ],
      "source": [
        "print('The action space of the environment is of dimension: {}'.format(env.action_space.n))\n",
        "print('The observation space of the environment is of dimension {}'.format(env.observation_space.sample().shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEi4LjFwwJXs"
      },
      "source": [
        "## Deep Q-Learning Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO9nq53sxpvg"
      },
      "source": [
        "**Replay Memory**: The agent needs a memory buffer to sample experience from"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OJN1J52YwN4a"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
        "\n",
        "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
        "\n",
        "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
        "        self.max_size, self.batch_size = size, batch_size\n",
        "        self.ptr, self.size, = 0, 0\n",
        "\n",
        "        # Device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def add(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        act: np.ndarray, \n",
        "        rew: float, \n",
        "        next_obs: np.ndarray, \n",
        "        done: bool,\n",
        "    ):\n",
        "        self.obs_buf[self.ptr] = obs\n",
        "        self.next_obs_buf[self.ptr] = next_obs\n",
        "        self.acts_buf[self.ptr] = act\n",
        "        self.rews_buf[self.ptr] = rew\n",
        "        self.done_buf[self.ptr] = done\n",
        "        self.ptr = (self.ptr + 1) % self.max_size\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "    def sample(self):\n",
        "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
        "\n",
        "        return (torch.from_numpy(self.obs_buf[idxs]).to(self.device),\n",
        "                torch.from_numpy(self.acts_buf[idxs]).long().to(self.device),\n",
        "                torch.from_numpy(self.rews_buf[idxs]).to(self.device),\n",
        "                torch.from_numpy(self.next_obs_buf[idxs]).to(self.device),\n",
        "                torch.from_numpy(self.done_buf[idxs]).to(self.device))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o46U8XU2Fwo"
      },
      "source": [
        "**DQN**: The Q network that returns Q-values for state-action pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZF6azuoI2jsy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self, action_size, input_dim=1):\n",
        "        super(DQN, self).__init__()\n",
        "\n",
        "        self.action_size = action_size \n",
        "\n",
        "        # Network\n",
        "        self.f1 =  nn.Linear(input_dim, 32)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.f2 = nn.Linear(32, 32)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.head = nn.Linear(32, self.action_size)\n",
        "\n",
        "        # Device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.to(self.device)\n",
        "\n",
        "        x = F.relu(self.bn1(self.f1(x)))\n",
        "        x = F.relu(self.bn2(self.f2(x)))\n",
        "        \n",
        "        return self.head(x)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLzFjW4h7540"
      },
      "source": [
        "**Agent**: The Python class featuring the main learning steps for the DQN agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BCf64x-z50m9"
      },
      "outputs": [],
      "source": [
        "from math import tau\n",
        "from torch import optim\n",
        "import random\n",
        "\n",
        "class Agent():\n",
        "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
        "\n",
        "    def __init__(self, dqn, memory, lr=1e-4, batch_size=64, update_every=5, gamma=0.99, tau=1e-3, epsilon=0.1, seed=0, render=False, optimal=False):\n",
        "        \"\"\"Initialize an Agent object.\n",
        "        \n",
        "        Params\n",
        "        ======\n",
        "            dqn (nn.Module): Module implementing the DQN\n",
        "            memory (object): Replay buffer object\n",
        "            seed (int): Random seed\n",
        "        \"\"\"\n",
        "\n",
        "        # Device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Q-Network\n",
        "        self.qnetwork_local = dqn.to(self.device)\n",
        "        self.qnetwork_target = dqn.to(self.device)\n",
        "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=lr)\n",
        "\n",
        "        # Other params\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "        self.update_every = update_every\n",
        "        self.gamma = gamma\n",
        "        self.tau = tau\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        self.render = render\n",
        "        self.optimal = optimal\n",
        "\n",
        "        # Replay memory\n",
        "        self.memory = memory\n",
        "        # Initialize time step (for updating every update_every steps)\n",
        "        self.t_step = 0\n",
        "\n",
        "    def episode(self, env, max_steps=1000):\n",
        "        \n",
        "        state = env.reset()\n",
        "        score = 0\n",
        "\n",
        "        if self.render:\n",
        "          env.render()\n",
        "\n",
        "        for _ in range(max_steps):\n",
        "            \n",
        "            action = self.act(state, self.epsilon)\n",
        "            a = env.step(action)\n",
        "            next_state, reward, done, _, info = env.step(action)\n",
        "            \n",
        "            if not(self.optimal):\n",
        "              self.step(state, action, reward, next_state, done)\n",
        "              \n",
        "            state = next_state\n",
        "            score += reward\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        return score\n",
        "\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        # Save experience in replay memory\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "        \n",
        "        # Learn every update_every time steps\n",
        "        self.t_step = (self.t_step + 1) % self.update_every\n",
        "        if self.t_step == 0:\n",
        "            # If enough samples are available in memory, get random subset and learn\n",
        "            if len(self.memory) >  self.batch_size:\n",
        "                experiences = self.memory.sample()\n",
        "                self.learn(experiences)\n",
        "\n",
        "    def learn(self, experiences):\n",
        "        \"\"\"Update value parameters using given batch of experience tuples.\n",
        "        Params\n",
        "        ======\n",
        "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
        "        \"\"\"\n",
        "        states, actions, rewards, next_states, dones = experiences\n",
        "        \n",
        "        # Get max predicted Q values (for next states) from target model\n",
        "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
        "        # Compute Q targets for current states \n",
        "        Q_targets = rewards.unsqueeze(1) + (self.gamma * Q_targets_next * (1 - dones.unsqueeze(1)))\n",
        "\n",
        "        # Get expected Q values from local model\n",
        "        Q_expected = self.qnetwork_local(states).gather(1, actions.unsqueeze(1))\n",
        "\n",
        "        # Compute loss\n",
        "        loss = F.mse_loss(Q_expected, Q_targets)\n",
        "        # Minimize the loss\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # ------------------- update target network ------------------- #\n",
        "        self.soft_update(self.qnetwork_local, self.qnetwork_target, self.tau)                     \n",
        "\n",
        "    def act(self, state, eps=0.):\n",
        "        \"\"\"Returns actions for given state as per current policy.\n",
        "        \n",
        "        Params\n",
        "        ======\n",
        "            state (array_like): current state\n",
        "            eps (float): epsilon, for epsilon-greedy action selection\n",
        "        \"\"\"\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(self.device)\n",
        "        self.qnetwork_local.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            action_values = self.qnetwork_local(state)\n",
        "        self.qnetwork_local.train()\n",
        "\n",
        "        # Epsilon-greedy action selection\n",
        "        if random.random() > eps:\n",
        "            return np.argmax(action_values.cpu().data.numpy())\n",
        "        else:\n",
        "            return random.choice(np.arange(self.qnetwork_local.action_size))\n",
        "\n",
        "    def soft_update(self, local_model, target_model, tau):\n",
        "        \"\"\"Soft update model parameters.\n",
        "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
        "        Params\n",
        "        ======\n",
        "            local_model (PyTorch model): weights will be copied from\n",
        "            target_model (PyTorch model): weights will be copied to\n",
        "            tau (float): interpolation parameter \n",
        "        \"\"\"\n",
        "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
        "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8Ek3uDFNF66"
      },
      "source": [
        "**Main training function**: the function that trains the agent on the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fNYHjjAjIkbz"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def DeepQLearning(env: gym.Env, agent: object, num_episodes: int, max_steps=1000, save_model=None):\n",
        "\n",
        "  reward_per_ep = list()\n",
        "\n",
        "  for i in tqdm(range(num_episodes)):\n",
        "    reward = agent.episode(env, max_steps=max_steps)\n",
        "    reward_per_ep.append(reward)\n",
        "  \n",
        "  if save_model is not None:\n",
        "    torch.save(agent.qnetwork_local.state_dict(), save_model)\n",
        "\n",
        "  return reward_per_ep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqyd52Do52Z1"
      },
      "source": [
        "## Training & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Jo9Sm8kc1xH"
      },
      "source": [
        "Define parameters and initialize modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yoTXrltuONr3"
      },
      "outputs": [],
      "source": [
        "# set parameters of the Agent and ReplayBuffer\n",
        "lr = 1e-4\n",
        "batch_size = 64\n",
        "update_every = 5 \n",
        "gamma = 0.99\n",
        "tau = 0.5\n",
        "epsilon = 0.1\n",
        "\n",
        "buffer_size=int(1e+4)\n",
        "seed=0\n",
        "\n",
        "# instantiate Q-network\n",
        "dqn = DQN(action_size=env.action_space.n,\n",
        "          input_dim=env.observation_space.shape[0])\n",
        "\n",
        "# instantiate memory buffer\n",
        "memory = ReplayBuffer(obs_dim=env.observation_space.shape[0],\n",
        "                      size=buffer_size,\n",
        "                      batch_size=batch_size)\n",
        "# instantiate agent\n",
        "agent = Agent(dqn,\n",
        "              memory,\n",
        "              lr=lr,\n",
        "              batch_size=batch_size,\n",
        "              update_every=update_every, \n",
        "              gamma=gamma,\n",
        "              tau=tau,\n",
        "              epsilon=epsilon)\n",
        "\n",
        "# number of episodes and file path to save the model\n",
        "num_episodes = 5000\n",
        "model_dir = os.path.join(root_dir, 'Models')\n",
        "save_model = os.path.join(model_dir, 'ffdqn_lunland_{}episodes.pth'.format(num_episodes))\n",
        "os.makedirs(model_dir, exist_ok =True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWf3Zk7Fc0qZ"
      },
      "source": [
        "Run training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiENSBENKeB8"
      },
      "outputs": [],
      "source": [
        "R = DeepQLearning(env, agent, num_episodes, save_model=save_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRjrzoZ_jjtU"
      },
      "source": [
        "Plot learning curve (i.e., average reward over fixed window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZe0Ei4nk2Wg"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def averagewindow(R, d=1):\n",
        "    n = len(R)\n",
        "    t = []\n",
        "    y = []\n",
        "    for i in range(0,int(n/d)):\n",
        "        t.append(np.mean(range(i*d,(i+1)*d)));\n",
        "        y.append(np.mean(R[i*d:min(n,(i+1)*d)]))\n",
        "    return t,y\n",
        "\n",
        "window = 10\n",
        "t,y = averagewindow(R, d=window)\n",
        "plt.plot(t, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnIQBBSXFxEU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# set parameters to evaluate agent\n",
        "agent.optimal = True\n",
        "agent.epsilon = 0.0\n",
        "vid_episodes = 5\n",
        "prefix = os.path.basename(save_model).split('.')[0]\n",
        "\n",
        "# use wrapper to record videos\n",
        "env_vid = RecordVideo(env, \n",
        "                      video_folder=video_folder,\n",
        "                      episode_trigger=lambda ep: (ep < vid_episodes),\n",
        "                      step_trigger=None,\n",
        "                      video_length=0,\n",
        "                      name_prefix=prefix,\n",
        "                      new_step_api=True\n",
        "                      )\n",
        "\n",
        "# use wrapper to record videos\n",
        "R_test = DeepQLearning(env_vid, agent, vid_episodes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEHynk-yihv3"
      },
      "outputs": [],
      "source": [
        "show_videos(video_folder, prefix=prefix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWkGOTUKl7ke"
      },
      "source": [
        "## Improve the current agent\n",
        "\n",
        "Pick (at least) one of the following tasks:\n",
        "\n",
        "1.   Look for better hyper-parameters of the algorithm (e.g., learning rate, batch size, epsilon, etc.).\n",
        "2.   Focus on the DQN architecture. For instance, add regularization techniques (e.g., dropout) in the current feed-forward network. Otherwise, you could embed temporal information into the Q network by using the [Frame Stack](https://www.gymlibrary.dev/api/wrappers/#available-wrappers) wrapper for feeding sequential data and [Recurrent](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)/[Attention](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html) layers for processing them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_aqGqecoUsO"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwzDwrrGprQE"
      },
      "source": [
        "# **2) Implement Deep RL Algorithm on `BipedalWalker-v3`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJwBAzaDqDL5"
      },
      "source": [
        "Further documentation for this environment is available [here](https://www.gymlibrary.dev/environments/box2d/bipedal_walker/).\n",
        "\n",
        "Note: this environment does not provide discrete actions. Therefore, the vanilla DQN algorithm can't be applied without discretizing etc.\n",
        "Implement a policy/actor-critic approach to deal with continous action spaces.\n",
        "\n",
        "Hint: You can modify the previously defined `Agent` class to implement the [Deep Deterministic Policy Gradient](https://arxiv.org/pdf/1509.02971.pdf) (DDPG) algorithm (check in particular Algorithm 1 of the paper). Most of the Deep RL algorthms need replay buffers, so the `ReplayBuffer` class can be directly re-used.\n",
        "Also, many implementations online (e.g., https://spinningup.openai.com/en/latest/_modules/spinup/algos/pytorch/ddpg/ddpg.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDAwCGVbvyUe"
      },
      "source": [
        "Instantiate `BipedalWalker-v3` environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_k9GPFFmv7cb"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\n",
        "    \"BipedalWalker-v3\",\n",
        "    new_step_api=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qShYTb4ewYAf"
      },
      "source": [
        "Record and show video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_SwG3FSwYAg"
      },
      "outputs": [],
      "source": [
        "prefix = 'bipwalk_random'\n",
        "\n",
        "record_video_randpol(env,\n",
        "                     video_length=100,\n",
        "                     episode_trigger=None,\n",
        "                     step_trigger=None,\n",
        "                     prefix=prefix,\n",
        "                     video_folder=video_folder)\n",
        "\n",
        "show_videos(video_folder, prefix=prefix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC4CFKgxyEGF"
      },
      "source": [
        "Update `Agent` class and write additional required classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0y4tIrTzWIo"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}